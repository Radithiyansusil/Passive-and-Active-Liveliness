# -*- coding: utf-8 -*-
"""Image_selfie_match.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10GXX84WbkJAMJUtSBPblDOE9JOlV27OI

Libraries
"""

!pip install deepface
!pip install boto3

# import packages and connect to server
from PIL import Image
import io
import pandas as pd
import numpy as np
from deepface import DeepFace
import cv2
import tempfile
import os
import boto3
import json

# from sklearn.metrics import accuracy_score, confusion_matrix
# from sklearn.metrics import precision_score, recall_score, f1_score
# import matplotlib.pyplot as plt
# import seaborn as sns

"""Function Code"""

# Read the AWS credentials and bucket name from the JSON file
path_credentials = "/content/sanket_s3.txt"
with open(path_credentials, 'r') as f:
    credentials = json.load(f)

AWS_ACCESS_KEY_ID = credentials['AWS_ACCESS_KEY_ID']
AWS_SECRET_ACCESS_KEY = credentials['AWS_SECRET_ACCESS_KEY']
AWS_STORAGE_BUCKET_NAME = "fatakpay-prod"
AWS_REGION = 'ap-south-1'
AWS_S3_REGION_NAME = 'ap-south-1'
AWS_S3_SIGNATURE_VERSION = 's3v4'
#print(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_STORAGE_BUCKET_NAME)

# Create an S3 resource
s3_resource = boto3.resource('s3',
                             aws_access_key_id=AWS_ACCESS_KEY_ID,
                             aws_secret_access_key=AWS_SECRET_ACCESS_KEY)

# Specify the bucket name and object key (file name)
bucket_name = AWS_STORAGE_BUCKET_NAME

# Retrieve the object from S3
#obj = s3_resource.Object(bucket_name, file_name)
#image_data = obj.get()['Body'].read()

file_path = r'/content/Addhar_and_selfie_pics.xlsx'


model_df = pd.read_excel(file_path)

def show_image_aws(image_path):
  # Load the image
  # Retrieve the object from S3
  obj = s3_resource.Object(bucket_name, image_path)
  image_data = obj.get()['Body'].read()
  image = Image.open(io.BytesIO(image_data))
  image = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2RGB)
  image= cv2.resize(image, (256, 256))
  image= Image.fromarray(image)

  # height, width,channels = image.shape
  return image

def show_image(image_path):
    obj = s3_resource.Object(bucket_name, image_path)
    image_data = obj.get()['Body'].read()
    image = Image.open(io.BytesIO(image_data))
    return image

def compare(image1, image2):
    # Save the PIL image objects as temporary files
    with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp1, tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp2:
        image1.save(temp1.name)
        image2.save(temp2.name)

    # Perform verification using the temporary file paths
    # result = DeepFace.verify(img1_path=temp1.name, img2_path=temp2.name, model_name='Facenet', enforce_detection=False)
    result_1 = DeepFace.verify(img1_path=temp1.name, img2_path=temp2.name, model_name='VGG-Face', enforce_detection=False)
    result_2=  DeepFace.verify(img1_path=temp1.name, img2_path=temp2.name, model_name='Facenet', enforce_detection=False)
    # Delete the temporary files
    temp1.close()
    temp2.close()
    if (result_1['distance']+result_2['distance'])/2>0.7:
        if result_1['distance']<0.7:
          return 1
        else:
          return 0
    elif (result_1['distance']+result_2['distance'])/2<0.7:
        if result_2['distance']>0.7:
          return 0
        else:
          return 1

"""Result"""

trial_data_start=0#should be defined here
trial_data_end=50#both start and end to decide number of data
trial_df=model_df.iloc[trial_data_start:trial_data_end]

y=trial_df.selfie_status
total_count=trial_df.shape[0]
trial_df.info()
print(y.value_counts())

image_paths_1 = trial_df['user_face_image'].tolist()  # replace with actual file paths
image_paths_2 = trial_df['selfie'].tolist()  # replace with actual file paths
result=[]
for i in range(total_count):
  image_1=show_image_aws(image_paths_1[i])
  image_2=show_image_aws(image_paths_2[i])
  result.append(compare(image_1, image_2))
  # print(compare(image_1, image_2))

#The result for every input of a customer
result