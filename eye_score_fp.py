# -*- coding: utf-8 -*-
"""load_eye_score.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1snoeMzPNr3tQfwB_0o5f1hciMKzepEqi

Libraries
"""

# !pip install boto3
!pip install mediapipe

import warnings
warnings.filterwarnings('ignore')

import mediapipe as mp
import cv2
import numpy as np

from PIL import Image
import io
import cv2
import tempfile
import os
import boto3
import json

# import pandas as pd
# from sklearn.metrics import accuracy_score, confusion_matrix
# from sklearn.metrics import precision_score, recall_score, f1_score
# import matplotlib.pyplot as plt
# import seaborn as sns

# detector = dlib.get_frontal_face_detector()
# predictor = dlib.shape_predictor('/content/drive/My Drive/shape_predictor_68_face_landmarks.dat')

# Read the AWS credentials and bucket name from the JSON file
path_credentials = "/content/sanket_s3.txt"
with open(path_credentials, 'r') as f:
    credentials = json.load(f)

AWS_ACCESS_KEY_ID = credentials['AWS_ACCESS_KEY_ID']
AWS_SECRET_ACCESS_KEY = credentials['AWS_SECRET_ACCESS_KEY']
AWS_STORAGE_BUCKET_NAME = "fatakpay-prod"
AWS_REGION = 'ap-south-1'
AWS_S3_REGION_NAME = 'ap-south-1'
AWS_S3_SIGNATURE_VERSION = 's3v4'
#print(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_STORAGE_BUCKET_NAME)

# Create an S3 resource
s3_resource = boto3.resource('s3',
                             aws_access_key_id=AWS_ACCESS_KEY_ID,
                             aws_secret_access_key=AWS_SECRET_ACCESS_KEY)

# Specify the bucket name and object key (file name)
bucket_name = AWS_STORAGE_BUCKET_NAME

# Retrieve the object from S3
#obj = s3_resource.Object(bucket_name, file_name)
#image_data = obj.get()['Body'].read()

"""Functions to run:"""

def show_image_aws(image_path):
  # Load the image
  # Retrieve the object from S3
  obj = s3_resource.Object(bucket_name, image_path)
  image_data = obj.get()['Body'].read()
  image = Image.open(io.BytesIO(image_data))
  image = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2RGB)
  image= cv2.resize(image, (512, 512))
  height, width,channels = image.shape
  return image,width,height

def show_image_local(image_path):
  image=Image.open(image_path)
  width, height = image.size
  image_1= image.convert("RGB")
  image = cv2.cvtColor(np.array(image_1), cv2.COLOR_BGR2RGB)
  image= cv2.resize(image, (512, 512))
  height, width,channels = image.shape
  return image,width,height

def X_Y(img,results,width,height):
  try:
    X_coordinate=[]
    Y_coordinate=[]
    # Iterate over each detected face
    for face_landmarks in results.multi_face_landmarks:
        # Iterate over each landmark point
        for landmark_id, landmark in enumerate(face_landmarks.landmark):
            # Convert the normalized coordinates to image coordinates
            x = int(landmark.x * width)
            y = int(landmark.y * height)
            X_coordinate.append(x)
            Y_coordinate.append(y)
    eye_right=((Y_coordinate[145]-Y_coordinate[159])+(Y_coordinate[144]-Y_coordinate[160])+(Y_coordinate[153]-Y_coordinate[158]))/(X_coordinate[133]-X_coordinate[33])
    eye_left=((Y_coordinate[374]-Y_coordinate[386])+(Y_coordinate[373]-Y_coordinate[387])+(Y_coordinate[380]-Y_coordinate[385]))/(X_coordinate[263]-X_coordinate[362])
    eye_score=(eye_left+eye_right)/2
    x_non=len(list(filter(lambda x: x <0 or x>width, X_coordinate)))
    y_non=len(list(filter(lambda y: y<0 or y>height, Y_coordinate)))
    score=eye_score-(x_non+y_non)/468+0.15 #correction term
    if score>1:
      return 1
    elif score>0:
      return score
    else:
      return 0
  except:
    return 0 #for now instead of Reupload to check the accuracy

mpDraw=mp.solutions.drawing_utils
mpFacemesh=mp.solutions.face_mesh
facemesh=mpFacemesh.FaceMesh(max_num_faces=1,static_image_mode=True)
# drawing_spec = mpDraw.DrawingSpec(color=(0, 0, 255), thickness=0, circle_radius=1)

"""Final function"""

image_path=input("Enter the image path:")# input the path here
img,width,height=show_image_aws(image_path)
# imgRGB=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
results=facemesh.process(img)
if results.multi_face_landmarks:
  for faceLms in results.multi_face_landmarks:
    mpDraw.draw_landmarks(img,faceLms,mpFacemesh.FACEMESH_FACE_OVAL,landmark_drawing_spec=drawing_spec)
# cv2_imshow(img)
score=X_Y(img,results,width,height)
print(f"The eye score is:{score}")
if score>0.5:
  print("Eye test Passed")
else:
  print("Eye test Failed,Reupload")
# print((score>0.5).astype(int))